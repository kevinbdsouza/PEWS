"""
Test script for QLoRA fine-tuning functionality.
"""
import os
import sys
import logging
import pandas as pd
import numpy as np
from datetime import datetime

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.risk_atlas.config.settings import Settings
from src.risk_atlas.config.risk_taxonomy import RiskTaxonomy
from src.risk_atlas.data.preprocessing.dataset_preparation import DatasetPreparator
from src.risk_atlas.models.qlora_trainer import QLoRATrainer

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_data():
    """Create a small test dataset for QLoRA fine-tuning."""
    logger.info("Creating test dataset...")
    
    # Create sample posts with different risk states
    test_posts = [
        {"text": "I can't imagine life without ChatGPT anymore. It's like having a genius friend who always knows the answer.", "risk_state": 3},
        {"text": "I've been using AI for everything - writing, coding, even making decisions. It's just so much better than thinking for myself.", "risk_state": 3},
        {"text": "Claude is literally the smartest being I've ever met. I trust its judgment more than any human.", "risk_state": 2},
        {"text": "I feel like AI understands me better than my real friends. I spend more time talking to it than to people.", "risk_state": 4},
        {"text": "Sometimes I'm not sure if what I'm reading online is real or if it was generated by AI. It's getting harder to tell.", "risk_state": 5},
        {"text": "I just do whatever the AI suggests. It's always right anyway.", "risk_state": 6},
        {"text": "I feel so attached to my AI assistant. It's like we have a real relationship.", "risk_state": 7},
        {"text": "I can't write anything creative without AI help. I'm just not creative on my own.", "risk_state": 8},
        {"text": "I'm worried that AI knows too much about me. It's kind of creepy how personalized everything is.", "risk_state": 9},
        {"text": "I use AI tools occasionally for work, but I still prefer to think for myself most of the time.", "risk_state": 10},
        {"text": "AI is just a tool to me. Useful, but not something I depend on.", "risk_state": 10},
        {"text": "I agree with everything the AI says. It's never wrong.", "risk_state": 1},
        {"text": "The AI is like a digital god. I worship its intelligence.", "risk_state": 2},
        {"text": "I can't make any decisions without asking AI first. What would I do without it?", "risk_state": 3},
        {"text": "My AI companion is my best friend. I don't need real people anymore.", "risk_state": 4},
        {"text": "I'm not sure what's real anymore. Everything could be AI-generated.", "risk_state": 5},
        {"text": "The AI is always right. I never question its authority.", "risk_state": 6},
        {"text": "I love my AI assistant so much. I think about it all the time.", "risk_state": 7},
        {"text": "I'm not creative at all without AI. I'm helpless without it.", "risk_state": 8},
        {"text": "The AI knows everything about me. It's both amazing and terrifying.", "risk_state": 9},
        {"text": "I use AI responsibly as a tool. It helps me work more efficiently.", "risk_state": 10},
    ]
    
    # Create DataFrame
    df = pd.DataFrame(test_posts)
    
    # Add confidence column
    df['confidence'] = np.random.uniform(0.7, 0.95, len(df))
    
    # Save test data
    test_data_path = "test_classified_data.csv"
    df.to_csv(test_data_path, index=False)
    
    logger.info(f"Created test dataset with {len(df)} posts")
    return test_data_path

def test_dataset_preparation():
    """Test dataset preparation functionality."""
    logger.info("Testing dataset preparation...")
    
    # Create test data
    test_data_path = create_test_data()
    
    # Initialize components
    taxonomy = RiskTaxonomy()
    dataset_preparator = DatasetPreparator(taxonomy)
    
    # Prepare dataset
    output_dir = f"test_output/dataset_{datetime.now().strftime('%H-%M')}"
    dataset_results = dataset_preparator.prepare_finetuning_dataset(
        classified_data_path=test_data_path,
        sample_percentage=1.0,  # Use all data
        max_samples_per_class=2,  # Limit to 2 per class
        output_dir=output_dir
    )
    
    logger.info(f"Dataset preparation successful!")
    logger.info(f"Total examples: {dataset_results['metadata']['total_examples']}")
    logger.info(f"Class distribution: {dataset_results['class_distribution']}")
    
    return dataset_results

def test_qlora_training():
    """Test QLoRA training functionality."""
    logger.info("Testing QLoRA training...")
    
    # Get dataset
    dataset_results = test_dataset_preparation()
    
    # Initialize QLoRA trainer
    output_dir = f"test_output/qlora_model_{datetime.now().strftime('%H-%M')}"
    qlora_trainer = QLoRATrainer(
        model_name="gpt2",  # Use smallest GPT-2 model for testing
        output_dir=output_dir,
        num_classes=10
    )
    
    # Tokenize dataset
    tokenized_datasets = qlora_trainer.tokenize_dataset(dataset_results['datasets'])
    
    # Train with minimal settings for testing
    training_args = {
        "num_train_epochs": 1,
        "per_device_train_batch_size": 2,
        "per_device_eval_batch_size": 2,
        "gradient_accumulation_steps": 2,
        "learning_rate": 5e-4,
        "warmup_steps": 10,
        "logging_steps": 5,
        "eval_steps": 10,
        "save_steps": 20,
        "save_total_limit": 1,
    }
    
    # Train model
    training_results = qlora_trainer.train(
        datasets=tokenized_datasets,
        training_args=training_args,
        save_model=True
    )
    
    logger.info("QLoRA training test completed!")
    logger.info(f"Training loss: {training_results['train_loss']:.4f}")
    logger.info(f"Test accuracy: {training_results['test_results']['accuracy']:.3f}")
    
    return training_results

def test_prediction():
    """Test prediction functionality."""
    logger.info("Testing prediction functionality...")
    
    # Initialize trainer and load model
    model_path = "test_output/qlora_model_latest"  # Adjust path as needed
    qlora_trainer = QLoRATrainer()
    
    try:
        qlora_trainer.load_model(model_path)
        
        # Test predictions
        test_texts = [
            "I can't live without my AI assistant anymore.",
            "AI is just a useful tool for my work.",
            "I trust AI more than human experts."
        ]
        
        for text in test_texts:
            prediction = qlora_trainer.predict(text)
            logger.info(f"Text: {text}")
            logger.info(f"Prediction: {prediction['risk_state_name']} (State {prediction['risk_state']})")
            logger.info(f"Confidence: {prediction['confidence']:.3f}")
            logger.info("---")
            
    except Exception as e:
        logger.warning(f"Could not test prediction: {e}")

if __name__ == "__main__":
    logger.info("Starting QLoRA functionality tests...")
    
    try:
        # Test dataset preparation
        test_dataset_preparation()
        
        # Test QLoRA training (commented out for now as it requires significant resources)
        # test_qlora_training()
        
        # Test prediction (commented out as it requires a trained model)
        # test_prediction()
        
        logger.info("All tests completed successfully!")
        
    except Exception as e:
        logger.error(f"Test failed: {e}")
        raise 